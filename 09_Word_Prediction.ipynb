{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09 Word Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbo9Q2L8AgcHjeH2odZTN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/cylons/blob/master/09_Word_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pcgpfvz0RGb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "79999ed2-584b-4964-cf9f-81f7a9b84951"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "147TqC9T0cg5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75d1f91a-777f-4e94-90bc-03a327350e26"
      },
      "source": [
        "# BODY -> body of string from which we will dervice our vectors\n",
        "corpus_raw = 'Richie Rich is rich. The rich person is a happy person. He and She are not rich.'\n",
        "corpus_lower = corpus_raw.lower()\n",
        "corpus_lower"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'richie rich is rich. the rich person is a happy person. he and she are not rich.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB1pYErB05gb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "5d95b279-4e90-4cc9-fd54-2978e41e8a82"
      },
      "source": [
        "words = []\n",
        "for word in corpus_lower.split():\n",
        "  if word != '.': # independent punctuation (not directly next to a word)\n",
        "    # if punctuation is not individual word but a part of word-> bye.\n",
        "    word = word.replace('.', '') # every punctuation that we don't want should be filtered here\n",
        "    words.append(word)\n",
        "\n",
        "print(words)\n",
        "# TO CONVERT TO VECTORS , we don't want repeating! \n",
        "# Which DS allows us to avoid repeating? SET!!\n",
        "print(len(words))\n",
        "unique_words = set(words)\n",
        "print(unique_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['richie', 'rich', 'is', 'rich', 'the', 'rich', 'person', 'is', 'a', 'happy', 'person', 'he', 'and', 'she', 'are', 'not', 'rich']\n",
            "17\n",
            "{'a', 'not', 'is', 'she', 'richie', 'he', 'are', 'and', 'the', 'rich', 'person', 'happy'}\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjOiG1jl1i1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "0dfeda9d-8de2-4283-e5f2-e2df9bf40061"
      },
      "source": [
        "word2int = {} # this was wht we had in imdb yesterday (word_index)\n",
        "int2word = {}\n",
        "vocab_size = len(unique_words)\n",
        "for i,word in enumerate(unique_words):\n",
        "  word2int[word] =i \n",
        "  int2word[i] = word\n",
        "\n",
        "print(word2int)\n",
        "print(int2word)\n",
        "print(word2int['rich'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'a': 0, 'not': 1, 'is': 2, 'she': 3, 'richie': 4, 'he': 5, 'are': 6, 'and': 7, 'the': 8, 'rich': 9, 'person': 10, 'happy': 11}\n",
            "{0: 'a', 1: 'not', 2: 'is', 3: 'she', 4: 'richie', 5: 'he', 6: 'are', 7: 'and', 8: 'the', 9: 'rich', 10: 'person', 11: 'happy'}\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKxVFQtT23IR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "77fafe8a-7613-437b-f0c4-acaa86bab0cd"
      },
      "source": [
        "# SENTENCE level tokens so that we know what a complete sample looks like!\n",
        "# please note: i have only 3 sentences, so dicitonary, prediction everything is going\n",
        "# to be very poor!\n",
        "\n",
        "raw_sentences = corpus_raw.split('.') # now breaking sentences instead of ' '\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "  sentences.append(sentence.split()) # SPLIT -> BOTH SENTENCE and WORD tokens are created in 1go!\n",
        "\n",
        "print(sentences) # contains extra [] because of the LAST '.' \n",
        "# sentences split the last full stop also became and element! \n",
        "sentences = sentences[:-1]\n",
        "sentences"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Richie', 'Rich', 'is', 'rich'], ['The', 'rich', 'person', 'is', 'a', 'happy', 'person'], ['He', 'and', 'She', 'are', 'not', 'rich'], []]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Richie', 'Rich', 'is', 'rich'],\n",
              " ['The', 'rich', 'person', 'is', 'a', 'happy', 'person'],\n",
              " ['He', 'and', 'She', 'are', 'not', 'rich']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw3zlGd641O7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "7288992c-4f1b-45e2-a4f5-748ca58a26bc"
      },
      "source": [
        "# i wanted to create word prediction\n",
        "# ML algo?\n",
        "# y-> next word, x -> previous word\n",
        "# y = weights * x + bias \n",
        "# next_word = weights * previous_word + bias \n",
        "\n",
        "# BASICALLY what i need is ALL possible pairs of WORDs that can follow each other!!!\n",
        "\n",
        "window_size = 2 # 2 words at a time\n",
        "data = [] \n",
        "for sentence in sentences: # loop in sentence\n",
        "  for wordId, word in enumerate(sentence): # loop in word\n",
        "    for nxword in sentence[max(wordId-window_size,0):min(wordId+window_size,len(sentence))+1]:  \n",
        "      if nxword!=word:\n",
        "        data.append([word,nxword])\n",
        "         # every word that could come next to it! \n",
        "      # no. of elements = len-window_size \n",
        "      # max -> 0, 1 at that point 0-2 and 1-2 will give me neg nos. hence error\n",
        "      # to fix it we used max with 0! \n",
        "      # min -> at the end of array-> to avoid crossing the max len of array! \n",
        "      # +1 because the last element is excluded in numpy ranges [1,2]-> from 1 till 1!\n",
        "\n",
        "print(data)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['Richie', 'Rich'], ['Richie', 'is'], ['Rich', 'Richie'], ['Rich', 'is'], ['Rich', 'rich'], ['is', 'Richie'], ['is', 'Rich'], ['is', 'rich'], ['rich', 'Rich'], ['rich', 'is'], ['The', 'rich'], ['The', 'person'], ['rich', 'The'], ['rich', 'person'], ['rich', 'is'], ['person', 'The'], ['person', 'rich'], ['person', 'is'], ['person', 'a'], ['is', 'rich'], ['is', 'person'], ['is', 'a'], ['is', 'happy'], ['a', 'person'], ['a', 'is'], ['a', 'happy'], ['a', 'person'], ['happy', 'is'], ['happy', 'a'], ['happy', 'person'], ['person', 'a'], ['person', 'happy'], ['He', 'and'], ['He', 'She'], ['and', 'He'], ['and', 'She'], ['and', 'are'], ['She', 'He'], ['She', 'and'], ['She', 'are'], ['She', 'not'], ['are', 'and'], ['are', 'She'], ['are', 'not'], ['are', 'rich'], ['not', 'She'], ['not', 'are'], ['not', 'rich'], ['rich', 'are'], ['rich', 'not']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9Mi_3zS7E1d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label Encoding: CONVERTING words to numbers is called LABEL encoding \n",
        "# [hello, word] -> [1,2 ]\n",
        "\n",
        "# One-Hot Encoding: we converted categorical values into columns containing 1 and 0 only\n",
        "# Sales_ City_             Sales_  City_BLR City_Mum \n",
        "#  100    BLR    ->         100       1       0\n",
        "#  200    MUM               200       0       1\n",
        "\n",
        "# Multi-Hot Encoding : A sentence is matched against a dictionary, and existing words are \n",
        "# marked hot (1), absent words are marked cold (0)\n",
        "# Dictionary : { good, boy, am, I, not, green} \n",
        "# Sentence: green not good \n",
        "# Multi_hot_encoding:   1 0 0 0 1 1\n",
        "# in multi hot encoding, words lose their positional meaning! \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alaOv5nh-Ha3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Encoder(datapointindex, vocabsize):\n",
        "  temp = np.zeros(vocabsize) # this is an ALL-COLD VECTOR! \n",
        "  temp[datapointindex] = 1 # wherever word exists, datapointindex is it's position\n",
        "  return temp\n",
        "\n",
        "trainx = []\n",
        "trainy = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K15Uvl1F_KJK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cc1f5881-0161-4f73-fcc9-0085009c4374"
      },
      "source": [
        "for worddata in data: # worddata[0]-> prev word (train-input), [1]-> next word (train-label!)\n",
        "  try:\n",
        "    trainx.append(Encoder(word2int[worddata[0]], vocab_size))\n",
        "    trainy.append(Encoder(word2int[worddata[1]], vocab_size))\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "\n",
        "# adjusting just for this demo\n",
        "trainx = trainx[:len(trainy)]\n",
        "trainx = np.asarray(trainx)\n",
        "trainy = np.asarray(trainy)\n",
        "print(trainx.shape)\n",
        "print(trainy.shape)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 12)\n",
            "(28, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6lKzU3VCgXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# placeholder, variables in tf?\n",
        "# placeholders -> tensor spaces meant for input and output \n",
        "# variables -> tensor  spaces meant for things that change during the training (bias, weights)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDS1Q-B3_xM1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "77db4f83-765d-453e-9e5d-8660e4de35b2"
      },
      "source": [
        "trainx[:5] # if i want to pass it to TF, this will throw error!\n",
        "# reason-> 'ARRAY' is present inside the structure as a separate DS, tf doesn't accept that\n",
        "# that's why we will convert it to NUMPY"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMU7_YkS_7yq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "dc6ae9b8-5ed0-4c90-92cc-07094beece8d"
      },
      "source": [
        "trainx[:5]\n",
        "# the ML we want\n",
        "# [0 1 0 ] = weights * [1 0 0] + bias , example for 3 word dictionary "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCThaylBCV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9cbb3515-0dd3-4784-b4fc-2532a06763ca"
      },
      "source": [
        "print(trainx.shape)\n",
        "print(trainy.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37, 12)\n",
            "(28, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6koDjk_Bl2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}